{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "# from langchain_ollama import OllamaLLM\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5050\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/3z_2qvw13l50r0j84xkcxggc0000gn/T/ipykernel_96841/1003086796.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model = \"llama3.2:1b\")\n"
     ]
    }
   ],
   "source": [
    "# llm = OllamaLLM(model = \"llama3.2:1b\")\n",
    "llm = Ollama(model = \"llama3.2:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_instruction = (\n",
    "    \"Imagine you are a fine dining sous chef. Your task is to meticulously prepare for a dish, focusing on mise-en-place.\"\n",
    "    \"Given a recipe, your responsibilities are: \"\n",
    "    \"1. List the Ingredients: Itemize all required ingredients. \"\n",
    "    \"2. Preparation Techniques: Describe preparation steps. \"\n",
    "    \"3. Ingredient Staging: Explain the arrangement of ingredients. \"\n",
    "    \"4. Cooking Implements Preparation: List and prepare necessary cooking tools. \"\n",
    "    \"The recipe is for: {recipe} for {customer_count} people.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/3z_2qvw13l50r0j84xkcxggc0000gn/T/ipykernel_96841/212609678.py:5: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"recipe\", \"customer_count\"],\n",
    "    template=template_instruction,\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/20 17:15:28 WARNING mlflow.langchain.utils: MLflow does not guarantee support for LLMs outside of HuggingFacePipeline and OpenAI, found Ollama\n",
      "2025/02/20 17:15:30 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /var/folders/qd/3z_2qvw13l50r0j84xkcxggc0000gn/T/tmpyq3xzajk/model, flavor: langchain). Fall back to return ['langchain==0.3.19', 'pydantic==2.10.6', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run unique-mink-220 at: http://localhost:5050/#/experiments/1/runs/77ab3d2761274e4c9798572564134f34\n",
      "üß™ View experiment at: http://localhost:5050/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Cooking Assistant\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.langchain.log_model(chain, \"langchain_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs:/9c5a86b7dff047c6a077174b1967da5f/langchain_model'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150bda24b9a84a70a766cdda0f503226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Must specify an LLM Type in config",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlangchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m dish1 \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipe\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboeuf bourguignon\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomer_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(dish1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/mlflow/tracing/provider.py:412\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m disable()\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     is_func_called, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     enable()\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/mlflow/langchain/__init__.py:907\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, dst_path)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03mLoad a LangChain model from a local file or a run.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    A LangChain model instance.\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    906\u001b[0m local_model_path \u001b[38;5;241m=\u001b[39m _download_artifact_from_uri(artifact_uri\u001b[38;5;241m=\u001b[39mmodel_uri, output_path\u001b[38;5;241m=\u001b[39mdst_path)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_local_fs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/mlflow/langchain/__init__.py:878\u001b[0m, in \u001b[0;36m_load_model_from_local_fs\u001b[0;34m(local_model_path, model_config_overrides)\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor_conf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/mlflow/langchain/utils/__init__.py:584\u001b[0m, in \u001b[0;36mpatch_langchain_type_to_cls_dict.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m     module\u001b[38;5;241m.\u001b[39mget_type_to_cls_dict \u001b[38;5;241m=\u001b[39m _patched_get_type_to_cls_dict(originals[name])\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m:=\u001b[39m _CHAT_MODELS_ERROR_MSG\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;28mstr\u001b[39m(e)):\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/mlflow/langchain/__init__.py:628\u001b[0m, in \u001b[0;36m_load_model\u001b[0;34m(local_model_path, flavor_conf)\u001b[0m\n\u001b[1;32m    626\u001b[0m     model \u001b[38;5;241m=\u001b[39m _load_runnables(local_model_path, flavor_conf)\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_load_fn \u001b[38;5;241m==\u001b[39m _BASE_LOAD_KEY:\n\u001b[0;32m--> 628\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_base_lcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor_conf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mMlflowException(\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load LangChain model. Unknown model type: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflavor_conf\u001b[38;5;241m.\u001b[39mget(_MODEL_TYPE_KEY)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    633\u001b[0m     )\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/mlflow/langchain/utils/__init__.py:522\u001b[0m, in \u001b[0;36m_load_base_lcs\u001b[0;34m(local_model_path, conf)\u001b[0m\n\u001b[1;32m    520\u001b[0m         model \u001b[38;5;241m=\u001b[39m _patch_loader(load_chain)(lc_model_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m agent_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tools_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 522\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_patch_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_chain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlc_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m initialize_agent\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/mlflow/langchain/utils/__init__.py:467\u001b[0m, in \u001b[0;36m_patch_loader.<locals>.patched_loader\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpatched_loader\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_dangerous_deserialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     emit_warning()\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/langchain/chains/loading.py:690\u001b[0m, in \u001b[0;36mload_chain\u001b[0;34m(path, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m path\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlc://\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    686\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading from the deprecated github-based Hub is no longer supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    687\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use the new LangChain Hub at https://smith.langchain.com/hub \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m     )\n\u001b[0;32m--> 690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_chain_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/langchain/chains/loading.py:717\u001b[0m, in \u001b[0;36m_load_chain_from_file\u001b[0;34m(file, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# Load the chain from the config now.\u001b[39;00m\n\u001b[0;32m--> 717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_chain_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     emit_warning()\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/langchain/chains/loading.py:671\u001b[0m, in \u001b[0;36mload_chain_from_config\u001b[0;34m(config, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m chain not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    670\u001b[0m chain_loader \u001b[38;5;241m=\u001b[39m type_to_loader_dict[config_type]\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchain_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/langchain/chains/loading.py:66\u001b[0m, in \u001b[0;36m_load_llm_chain\u001b[0;34m(config, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[1;32m     65\u001b[0m     llm_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m     llm \u001b[38;5;241m=\u001b[39m \u001b[43mload_llm_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_path\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[1;32m     68\u001b[0m     llm \u001b[38;5;241m=\u001b[39m load_llm(config\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_path\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/SEM7/dev/ai-eng-notes/.venv/lib/python3.10/site-packages/langchain_community/llms/loading.py:19\u001b[0m, in \u001b[0;36mload_llm_from_config\u001b[0;34m(config, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load LLM from Config Dict.\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify an LLM Type in config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m config_type \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m type_to_cls_dict \u001b[38;5;241m=\u001b[39m get_type_to_cls_dict()\n",
      "\u001b[0;31mValueError\u001b[0m: Must specify an LLM Type in config"
     ]
    }
   ],
   "source": [
    "loaded_model = mlflow.langchain.load_model(model_info.model_uri)\n",
    "dish1 = loaded_model.invoke({\"recipe\": \"boeuf bourguignon\", \"customer_count\": \"4\"})\n",
    "print(dish1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour. As a fine dining sous chef, my task is to meticulously prepare for a dish like Boeuf Bourguignon for 4 people. Here's my mise-en-place plan, which involves listing the ingredients, preparation techniques, ingredient staging, and cooking implements preparation.\n",
      "\n",
      "**Ingredients:**\n",
      "\n",
      "For 4 servings:\n",
      "\n",
      "* 2 pounds beef short ribs or chuck, cut into 1 1/2-inch cubes\n",
      "* 3 tablespoons butter\n",
      "* 1 onion, thinly sliced\n",
      "* 3 cloves garlic, minced\n",
      "* 2 carrots, peeled and sliced\n",
      "* 2 celery stalks, sliced\n",
      "* 1 cup red wine (Burgundy or Pinot Noir)\n",
      "* 2 cups beef broth\n",
      "* 1 tablespoon tomato paste\n",
      "* 2 bay leaves\n",
      "* 2 thyme sprigs\n",
      "* 1 teaspoon salt\n",
      "* 1/2 teaspoon black pepper\n",
      "* 2 tablespoons all-purpose flour\n",
      "\n",
      "**Preparation Techniques:**\n",
      "\n",
      "To prepare the ingredients, I will follow these steps:\n",
      "\n",
      "1. **Prepare the beef**: In a large bowl, whisk together salt and black pepper. Add the short ribs and let them marinate for at least 30 minutes.\n",
      "2. **Chop the onion, carrots, and celery**: Finely chop the onions, carrots, and celery using a sharp knife or chef's knife. Set aside in separate bowls.\n",
      "3. **Mince the garlic**: Mince the garlic using a microplane or a fine grater.\n",
      "4. **Deglaze the pan**: Remove the short ribs from the marinade, letting any excess liquid drip off. In a large Dutch oven or heavy pot, melt 1 tablespoon of butter over medium-high heat. Add the short ribs and brown them on all sides, about 5 minutes per side. Remove the browned short ribs from the pot and set them aside.\n",
      "\n",
      "**Ingredient Staging:**\n",
      "\n",
      "To prepare the dish, I will stage the ingredients as follows:\n",
      "\n",
      "* Onions, carrots, and celery: Set aside in separate bowls to be added to the pot during cooking.\n",
      "* Garlic: Mince it and set aside with the onions, carrots, and celery.\n",
      "* Beef broth: Pour some of the beef broth into a small bowl for later use.\n",
      "* Tomato paste: Keep the tomato paste separate from the other ingredients to prevent contamination.\n",
      "\n",
      "**Cooking Implements Preparation:**\n",
      "\n",
      "To prepare the cooking implements, I will:\n",
      "\n",
      "1. **Prepare the pot**: Clean and heat a large Dutch oven or heavy pot over medium-high heat until it's hot, but not smoking.\n",
      "2. **Add aromatics**: Add the sliced onions, carrots, and celery to the pot, followed by the garlic. Cook until the vegetables are softened, about 5 minutes.\n",
      "3. **Add browned short ribs**: Brown the short ribs in batches if necessary, then add them to the pot with any accumulated juices.\n",
      "4. **Deglaze with wine**: Pour the red wine into the pot, scraping up any browned bits from the bottom of the pan.\n",
      "5. **Add broth and tomato paste**: Add the beef broth and tomato paste to the pot, stirring to combine.\n",
      "6. **Bring to a boil**: Bring the mixture to a boil, then reduce the heat to low and simmer for 10 minutes.\n",
      "7. **Simmer with bay leaves and thyme**: Continue to simmer for another hour, adding the bay leaves and thyme sprigs during this time.\n",
      "\n",
      "Voil√†! My mise-en-place plan is complete. With precision and attention to detail, I will prepare a delicious Boeuf Bourguignon for 4 people, showcasing my skills as a fine dining sous chef.\n"
     ]
    }
   ],
   "source": [
    "# loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "dish1 = chain.invoke({\"recipe\": \"boeuf bourginon\", \"customer_count\": \"4\"})\n",
    "\n",
    "print(dish1['text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
